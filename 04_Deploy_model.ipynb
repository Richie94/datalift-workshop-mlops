{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy model as a webservice on Azure Kubernetes Service"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "1. [Prerequisites](#prerequisites)\n",
    "\n",
    "2. [Initialize workspace](#workspace)\n",
    "\n",
    "3. [Deploy Model to AKS](#deploymodel)\n",
    "\n",
    "- a) [Create scoring file](#scoringfile)\n",
    "- b) [Define Enviroment](#env)\n",
    "- c) [Deployment configuration](#configfile)\n",
    "- d  [Deploy Webservice](#webservice)\n",
    "- e) [Test Webservice](#testservice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Prerequisites <a id='prerequisites'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.41.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import azureml.core\n",
    "\n",
    "# display the core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Initialize workspace <a id='workspace'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ml-ws-aiplatform-dev\n",
      "rg-aiplatform-dev\n",
      "northeurope\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "from azureml.core.model import Model\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location, sep = '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Deploy model <a id='deploymodel'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Create a scoring script <a id='scoringfile'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile score.py\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import onnxruntime\n",
    "import time\n",
    "from azureml.core.model import Model\n",
    "from azureml.monitoring import ModelDataCollector\n",
    "from inference_schema.schema_decorators import input_schema, output_schema\n",
    "from inference_schema.parameter_types.numpy_parameter_type import NumpyParameterType\n",
    "\n",
    "def init():\n",
    "    global model, scaler, input_name, label_name, inputs_dc, prediction_dc\n",
    "    \n",
    "\n",
    "    scaler_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'model-scaler/1/model-scaler.pkl')\n",
    "    # deserialize the model file back into a sklearn model\n",
    "    scaler = joblib.load(scaler_path)\n",
    "    \n",
    "    model_onnx = os.path.join(os.getenv('AZUREML_MODEL_DIR'), 'support-vector-classifier/1/svc.onnx')\n",
    "    # print(os.listdir(model_onnx))\n",
    "    model = onnxruntime.InferenceSession(model_onnx, None)\n",
    "    input_name = model.get_inputs()[0].name\n",
    "    label_name = model.get_outputs()[0].name\n",
    "    \n",
    "    # variables to monitor model input and output data\n",
    "    inputs_dc = ModelDataCollector(\"Support vector classifier model\", designation=\"inputs\", feature_names=[\"feat1\", \"feat2\", \"feat3\", \"feat4\", \"feat5\", \"feat6\", \"feat7\"])\n",
    "    prediction_dc = ModelDataCollector(\"Support vector classifier model\", designation=\"predictions\", feature_names=[\"weatherprediction\"])\n",
    "\n",
    "    \n",
    "@input_schema('data', NumpyParameterType(np.array([[34.927778, 0.24, 7.3899, 83, 16.1000, 1016.51, 1]])))\n",
    "@output_schema(NumpyParameterType(np.array([0])))\n",
    "def run(data):\n",
    "                try: \n",
    "                    data = scaler.fit_transform(data.reshape(1, 7))\n",
    "                    inputs_dc.collect(data)\n",
    "                    \n",
    "                    # model inference\n",
    "                    result = model.run([label_name], {input_name: data.astype(np.float32)})[0]\n",
    "                    # this call is saving model output data into Azure Blob\n",
    "                    prediction_dc.collect(result)\n",
    "\n",
    "                 \n",
    "                except Exception as e:   \n",
    "                    result = 'error'\n",
    "                    prediction_dc.collect(result)\n",
    "                    \n",
    "                return result.tolist()            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Define Environment <a id='env'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "Environment(name=\"myenv\")\n",
    "\n",
    "#env = Environment.get(workspace=ws, name=\"AzureML-Minimal\")\n",
    "env = Environment.get(workspace=ws, name=\"AzureML-Minimal\").clone('myenv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pip_package in [\"numpy\", \"onnxruntime\", \"joblib\", \"azureml-core\", \"azureml-monitoring\", \"azureml-defaults\", \"scikit-learn==0.20.3\", \"inference-schema\", \"inference-schema[numpy-support]\"]:\n",
    "    env.python.conda_dependencies.add_pip_package(pip_package)\n",
    "\n",
    "inference_config = InferenceConfig(entry_script='score.py',\n",
    "                                    environment=env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Deployment Configuration <a id='configfile'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "aks_config = AksWebservice.deploy_configuration(collect_model_data=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Deploy web service <a id='webservice'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.core.compute import AksCompute, ComputeTarget\n",
    "\n",
    "# Choose a name for your AKS cluster\n",
    "aks_name = 'port-aks' \n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    aks_target = ComputeTarget(workspace=ws, name=aks_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # Use the default configuration (can also provide parameters to customize)\n",
    "    prov_config = AksCompute.provisioning_configuration()\n",
    "\n",
    "    # Create the cluster\n",
    "    aks_target = ComputeTarget.create(workspace = ws, \n",
    "                                    name = aks_name, \n",
    "                                    provisioning_configuration = prov_config)\n",
    "\n",
    "if aks_target.get_status() != \"Succeeded\":\n",
    "    aks_target.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Model(ws, 'scaler')\n",
    "model2 = Model(ws, 'support-vector-classifier')\n",
    "\n",
    "service_name = 'weather-aks-prediction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Model.deploy(ws, service_name, models=[model1, model2], inference_config=inference_config, deployment_config=aks_config, deployment_target=aks_target,overwrite=True)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.update(enable_app_insights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### e) Test web service <a id='testservice'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.scoring_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.swagger_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "input_payload = json.dumps({\n",
    "    'data': [[34.927778, 0.24, 7.3899, 83, 16.1000, 1016.51, 1]],\n",
    "    'method': 'predict'  # If you have a classification model, you can get probabilities by changing this to 'predict_proba'.\n",
    "})\n",
    "\n",
    "output = service.run(input_payload)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
